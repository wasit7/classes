{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "\\beta_{i+1}&\\Leftarrow&\\beta_{i}-\\alpha \\frac {\\partial{J}} {\\partial \\beta}\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "## Sigmoid function\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "a(z)&=&\\frac{1}{1+e^{-z}}\\\\\n",
    "\\frac {d{a}} {d z}&=&a(1-a)\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "## Hyperbolic Tan function\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "a(z)&=&{tanh(z)}\\\\\n",
    "\\frac {d{a}} {d z}&=&1-a^2\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "******\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Gradient Descent\n",
    "For a simple GD please show results from first 5 iterations. Note that all parameters in this question are scalar.\n",
    "Let\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "J&=& \\frac{1}{2}(y_p-3)^2 \\\\\n",
    "y_p &=& 2w - 1\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "## Q1.1\n",
    "write down the update method for $w$ to minimize the value of J using GD technique \\[ 5\\]\n",
    "\n",
    "### ms1.1\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "w_{i+1} &\\Leftarrow& w_{i} - \\alpha \\frac {d{J}} {d w}\\\\\n",
    "w_{i+1} &\\Leftarrow& w_{i} - \\alpha \\frac {d{J}} {d y_p} \\frac {d{y_p}} {d w}\\\\\n",
    "w_{i+1} &\\Leftarrow&w_{i} - \\alpha (y_p-3)(2)\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "\n",
    "## Q1.2\n",
    "Using GD method and update $w$ for 5 iterations. Let $\\alpha=0.1$ and $w_{i=0}=-1.0$. \\[5\\]\n",
    "\n",
    "\n",
    "| $i$ | $w_i$  | $w_{i+1}$  |\n",
    "| --- |:------:| ----------:|\n",
    "| 0   | -1.0   |..........       |\n",
    "| 1   |  ..... |..........       |\n",
    "| 2   |  ..... |..........       |\n",
    "| 3   |  ..... |..........       |\n",
    "| 4   |  ..... |..........       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1.00  0.20 \n",
      "1  0.20  0.92 \n",
      "2  0.92  1.35 \n",
      "3  1.35  1.61 \n",
      "4  1.61  1.77 \n"
     ]
    }
   ],
   "source": [
    "#ms1.2\n",
    "import numpy as np\n",
    "alpha=0.1\n",
    "wi=-1.0\n",
    "for i in range(5):\n",
    "    yp=2.0*wi-1.0\n",
    "    wf=wi-alpha*(yp-3.0)*(2.0)\n",
    "    print(\"%d %5.2f %5.2f \"%(i,wi,wf))\n",
    "    wi=wf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Single Layer Perceptron\n",
    "\n",
    "From a simple single layer perceptron using GD for update $w_0$ and $b_0$ to reduce $J$, where $\\ast$ is element-wise multiplication\n",
    "\\begin{eqnarray}\n",
    "    g(h)&=&\\frac{1}{1+e^{-h}}\\nonumber\\\\\n",
    "       J&=&\\frac{1}{2}(y_p - y_t)^2\\nonumber\\\\\n",
    "       y_p&=&g(x.w_0 + b_0)\\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "# Q2.1\n",
    "Write update equations to adjust $w_0$. \\[5\\]\n",
    "\n",
    "\n",
    "# Q2.2\n",
    "Write update equations to adjust $b_0$ \\[5\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ms2.1\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "w_{i+1} &\\Leftarrow& w_{i} - \\alpha \\frac {d{J}} {d w}\\\\\n",
    "w_{i+1} &\\Leftarrow& w_{i} - \\alpha \\frac {d{J}} {d y_p} \\frac {d{y_p}} {d w}\\\\\n",
    "w_{i+1} &\\Leftarrow&w_{i} - \\alpha (y_p-y_t)y_p(1-y_p)x\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "### ms2.1\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "b_{i+1} &\\Leftarrow& b_{i} - \\alpha \\frac {d{J}} {d b}\\\\\n",
    "b_{i+1} &\\Leftarrow& b_{i} - \\alpha \\frac {d{J}} {d y_p} \\frac {d{y_p}} {d b}\\\\\n",
    "b_{i+1} &\\Leftarrow& b_{i} - \\alpha (y_p-y_t)y_p(1-y_p)\\\\\n",
    "\\end{eqnarray*}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  wi:-1.00  wf:-0.99  bi: 0.00  bf: 0.00  yp:0.12  yt:0.50\n",
      " 20  wi:-0.83  wf:-0.82  bi: 0.09  bf: 0.09  yp:0.17  yt:0.50\n",
      " 40  wi:-0.64  wf:-0.63  bi: 0.18  bf: 0.19  yp:0.25  yt:0.50\n",
      " 60  wi:-0.47  wf:-0.46  bi: 0.27  bf: 0.27  yp:0.34  yt:0.50\n",
      " 80  wi:-0.35  wf:-0.34  bi: 0.33  bf: 0.33  yp:0.41  yt:0.50\n",
      "100  wi:-0.28  wf:-0.28  bi: 0.36  bf: 0.36  yp:0.45  yt:0.50\n",
      "120  wi:-0.24  wf:-0.24  bi: 0.38  bf: 0.38  yp:0.47  yt:0.50\n",
      "140  wi:-0.22  wf:-0.22  bi: 0.39  bf: 0.39  yp:0.49  yt:0.50\n",
      "160  wi:-0.21  wf:-0.21  bi: 0.39  bf: 0.39  yp:0.49  yt:0.50\n",
      "180  wi:-0.21  wf:-0.21  bi: 0.40  bf: 0.40  yp:0.50  yt:0.50\n"
     ]
    }
   ],
   "source": [
    "#ms1.2\n",
    "import numpy as np\n",
    "def g(h):\n",
    "    return 1.0/(1+np.exp(-h))\n",
    "alpha=0.1\n",
    "wi=-1.0\n",
    "bi=0\n",
    "x=2.0\n",
    "yt=0.5\n",
    "for i in range(200):\n",
    "    yp=g(x*wi+bi)\n",
    "    wf=wi-alpha*(yp-yt)*yp*(1.0-yp)*x\n",
    "    bf=bi-alpha*(yp-yt)*yp*(1.0-yp)\n",
    "    if i%20==0:\n",
    "        print(\"%3d  wi:%5.2f  wf:%5.2f  bi:%5.2f  bf:%5.2f  yp:%4.2f  yt:%4.2f\"%(i,wi,wf,bi,bf,yp,yt))\n",
    "    wi=wf\n",
    "    bi=bf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Multiple Layer Perceptron\n",
    "\n",
    "For a two Layer Perceptron network we can use GD to minimize loss as following; \n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "    g(z)&=&\\frac{1}{1+e^{-z}}\\nonumber\\\\\n",
    "    J&=&\\frac{1}{2}(y_p - y_t)^2\\nonumber\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    ", the input $x$ and the output $y$ attach to the network\n",
    "\n",
    "$\n",
    "\\begin{eqnarray}    \n",
    "    a_0 &\\Leftarrow &x\\nonumber\\\\\n",
    "    y_p& \\Leftarrow &a_2\\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "$\n",
    "\n",
    "\n",
    ", forward network\n",
    "\n",
    "$\n",
    "\\begin{eqnarray}\n",
    "z_0&=&a_0.w_0+b_0\\nonumber\\\\\n",
    "a_1&=&g(z_0)\\nonumber\\\\\n",
    "z_1&=&a_1.w_1+b_1\\nonumber\\\\\n",
    "a_2&=&g(z_1)\\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "$\n",
    "\n",
    "\n",
    "## Q3.1 \n",
    "Explain the calculation process to $w_0$ in order to minimize $J$. \\[5\\]\n",
    "\n",
    "$\n",
    "\\begin{eqnarray}\n",
    "    \\frac{\\partial J}{\\partial w_0} &=& \\frac{\\partial J}{\\partial y_p} \\frac{\\partial y_p}{\\partial a_2} \n",
    "\\frac{\\partial a_2}{\\partial z_1} \\frac{\\partial z_1}{\\partial a_1} \\frac{\\partial a_1}{\\partial z_0} \\frac{\\partial z_0}{\\partial w_0} \\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "$\n",
    "\n",
    "## Q3.2\n",
    "Let input size of the variable as following. Write size of all variables \\[5\\]\n",
    "\n",
    "\n",
    "| $variable$ | $size$  |\n",
    "| ------   |:------:|\n",
    "| $x$     | $\\textbf{[3x1]}$   |\n",
    "| $w_0$   |  $[3x4]$ |\n",
    "| $b_0$   |  $\\textbf{[4]}$ |\n",
    "| $z_0$   |  $[4x1]$ |\n",
    "| $a_1$   |  $[4x1]$ |\n",
    "| $w_1$   |  $[4x2]$ |\n",
    "| $b_1$   |  $[2]$ |\n",
    "| $z_1$   |  $[2x1]$ |\n",
    "| $a_2$   |  $[2x1]$ |\n",
    "| $y_p$   |  $[2x1]$ |\n",
    "| $y_t$   |  $\\textbf{[2x1]}$ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Regularization and Training method\n",
    "Describe the objective and process of the following regularization methods\n",
    "1. Regularization penalty in cost function \\[2\\]\n",
    "2. Dropout \\[2\\]\n",
    "3. Early stopping \\[1\\]\n",
    "4. Gradient Descent \\[1\\]\n",
    "5. Stochastic Gradient Descent \\[2\\]\n",
    "6. Mini-batch \\[2\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ms4\n",
    "\n",
    "1. to **maintain bias and weight** in the **stable range**\n",
    "2. **deactivating some neurons** to reduce training complexity and genrate a **generalized model** and not heavily rely on a specific neural pathway\n",
    "3. **avoid overfitting** by early stopping the training process when there is **no/less progress**\n",
    "4. a method to adjust internal parameters to **minimize the loss**, adjusting the parameters **once per episode**\n",
    "5. **update** the parameters **once per data**\n",
    "6. **update** the parameters **once per batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
