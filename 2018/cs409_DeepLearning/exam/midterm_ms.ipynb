{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "\\beta_{i+1}&\\Leftarrow&\\beta_{i}-\\alpha \\frac {\\partial{J}} {\\partial \\beta}\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "## Sigmoid function\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "a(z)&=&\\frac{1}{1+e^{-z}}\\\\\n",
    "\\frac {d{a}} {d z}&=&a(1-a)\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "## Hyperbolic Tan function\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "a(z)&=&{tanh(z)}\\\\\n",
    "\\frac {d{a}} {d z}&=&1-a^2\\\\\n",
    "\\end{eqnarray*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. Gradient Descent\n",
    "For a simple GD please show results from first 5 iterations. Note that all parameters in this question are scalar.\n",
    "Let\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "J&=& \\frac{1}{2}(y_p-3)^2 \\\\\n",
    "y_p &=& 2w - 1\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "## Q1.1\n",
    "write down the update method for $w$ to minimize the value of J using GD technique \\[ 5\\]\n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "w_{i+1} &\\Leftarrow& w_{i} - \\alpha \\frac {d{J}} {d w}\\\\\n",
    "w_{i+1} &\\Leftarrow& w_{i} - \\alpha \\frac {d{J}} {d y_p} \\frac {d{y_p}} {d w}\\\\\n",
    "w_{i+1} &\\Leftarrow&w_{i} - \\alpha (y_p-3)(2)\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    "\n",
    "## Q1.2\n",
    "Using GD method and update $w$ for 5 iterations. Let $\\alpha=0.1$ and $w_{i=0}=-1.0$. \\[5\\]\n",
    "\n",
    "\n",
    "| $i$ | $w_i$  | $w_{i+1}$  |\n",
    "| --- |:------:| ----------:|\n",
    "| 0   | -1.0   |.....       |\n",
    "| 1   |  ..... |.....       |\n",
    "| 2   |  ..... |.....       |\n",
    "| 3   |  ..... |.....       |\n",
    "| 4   |  ..... |.....       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. Single Layer Perceptron\n",
    "\n",
    "From a simple single layer perceptron using GD for update $w_0$ and $b_0$ to reduce $J$, where $\\ast$ is element-wise multiplication\n",
    "\\begin{eqnarray}\n",
    "    g(h)&=&\\frac{1}{1+e^{-h}}\\nonumber\\\\\n",
    "       J&=&\\frac{1}{2}(y_p - y_t)^2\\nonumber\\\\\n",
    "       y_p&=&g(x.w_0 + b_0)\\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "\n",
    "# Q2.1\n",
    "Write update equations to adjust $w_0$. \\[5\\]\n",
    "\n",
    "# Q2.2\n",
    "Write update equations to adjust $b_0$ \\[5\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. Multiple Layer Perceptron\n",
    "\n",
    "For a two Layer Perceptron network we can use GD to minimize loss as following; \n",
    "\n",
    "$\n",
    "\\begin{eqnarray*}\n",
    "    g(z)&=&\\frac{1}{1+e^{-z}}\\nonumber\\\\\n",
    "    J&=&\\frac{1}{2}(y_p - y_t)^2\\nonumber\\\\\n",
    "\\end{eqnarray*}\n",
    "$\n",
    "\n",
    ", the input $x$ and the output $y$ attach to the network\n",
    "\n",
    "$\n",
    "\\begin{eqnarray}    \n",
    "    a_0 &\\Leftarrow &x\\nonumber\\\\\n",
    "    y_p& \\Leftarrow &a_2\\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "$\n",
    "\n",
    "\n",
    ", forward network\n",
    "\n",
    "$\n",
    "\\begin{eqnarray}\n",
    "z_0&=&a_0.w_0+b_0\\nonumber\\\\\n",
    "a_1&=&g(z_0)\\nonumber\\\\\n",
    "z_1&=&a_1.w_1+b_1\\nonumber\\\\\n",
    "a_2&=&g(z_1)\\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "$\n",
    "\n",
    "\n",
    "## Q3.1 \n",
    "Explain the calculation process to $w_0$ in order to minimize $J$. \\[5\\]\n",
    "\n",
    "$\n",
    "\\begin{eqnarray}\n",
    "    \\frac{\\partial J}{\\partial w_0} &=& \\frac{\\partial J}{\\partial y_p} \\frac{\\partial y_p}{\\partial a_2} \n",
    "\\frac{\\partial a_2}{\\partial z_1} \\frac{\\partial z_1}{\\partial a_1} \\frac{\\partial a_1}{\\partial z_0} \\frac{\\partial z_0}{\\partial w_0} \\nonumber\\\\\n",
    "\\end{eqnarray}\n",
    "$\n",
    "\n",
    "## Q3.2\n",
    "Let input size of the variable as following. Write size of all variables \\[5\\]\n",
    "\n",
    "\n",
    "| $variable$ | $size$  |\n",
    "| ------   |:------:|\n",
    "| $x$     | $[3x1]$   |\n",
    "| $w_0$   |  $[3x4]$ |\n",
    "| $b_0$   |  $[4]$ |\n",
    "| $z_0$   |  $[4x1]$ |\n",
    "| $a_1$   |  $[4x1]$ |\n",
    "| $w_1$   |  $[4x2]$ |\n",
    "| $b_1$   |  $[2]$ |\n",
    "| $z_1$   |  $[2x1]$ |\n",
    "| $a_2$   |  $[2x1]$ |\n",
    "| $y_p$   |  $[2x1]$ |\n",
    "| $y_t$   |  $[2x1]$ |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 Regularization and Training method\n",
    "Describe the objective and process of the following regularization methods\n",
    "1. Regularization penalty in cost function \\[2\\]\n",
    "2. Dropout \\[2\\]\n",
    "3. Early stopping \\[1\\]\n",
    "4. Gradient descent \\[1\\]\n",
    "5. Stochastic \\[2\\]\n",
    "6. Mini-batch \\[2\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
